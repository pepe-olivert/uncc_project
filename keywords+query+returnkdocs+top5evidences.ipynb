{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importamos los paquetes que necesitamos. \n",
    "### 1- Función: sustract keywords: Extrae las keywords de la claim\n",
    "### 2- Función build query: Monta la query en el formato de whoosh para buscar en la colección\n",
    "### 3- Función search: Dada una claim, el directorio del índice y una k, te devuelve los documentos que tienen relevancia dada la claim. Si hay más documentos que k te devuelve k documentos, sino te los devuelve todos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Pepe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from whoosh.index import open_dir\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from whoosh.qparser import QueryParser\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import AutoTokenizer, AutoModel,AutoModelForTokenClassification,AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch.nn.functional as F\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "from keybert import KeyBERT\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformers import TrainingArguments, AdamW\n",
    "import torch.nn as nn\n",
    "\n",
    "kw_model = KeyBERT()\n",
    "\n",
    "modelSBERT = SentenceTransformer('mitra-mir/setfit-model-Feb11-Misinformation-on-Media-Traditional-Social')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/stsb-roberta-large')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/stsb-roberta-large')\n",
    "\n",
    "def sustract_keywords(query):\n",
    "    resul=[]\n",
    "    kw = kw_model.extract_keywords(query,keyphrase_ngram_range=(1, 1), stop_words=None)\n",
    "    for k,v in kw:\n",
    "        resul.append(k)\n",
    "        \n",
    "    return resul\n",
    "\n",
    "def build_query(lista):\n",
    "    new_l=[]\n",
    "    for elem in lista:\n",
    "        \n",
    "        new_l.append(f'evidences:{elem} OR keywords:{elem}')\n",
    "        \n",
    "    return \" OR \".join(new_l)\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "def search(q,dirindex,k):\n",
    "    keyw=sustract_keywords(q)\n",
    "    \n",
    "    print(f'-> Keywords of the query: {keyw}')\n",
    "    \n",
    "    \n",
    "    ix=open_dir(dirindex)\n",
    "    \n",
    "    personal_query=build_query(keyw)\n",
    "    full_query=f'query --> {personal_query}'\n",
    "\n",
    "\n",
    "    print(full_query)\n",
    "\n",
    "    with ix.searcher() as searcher:\n",
    "        parser=QueryParser(\"evidences\",ix.schema)\n",
    "        query=parser.parse(personal_query)\n",
    "\n",
    "        results=searcher.search(query,limit=None)\n",
    "        ev=[]\n",
    "        for r in results:\n",
    "            print(f'-> {r[\"evidences\"]} ({r[\"keywords\"]})')\n",
    "            ev.append(r[\"evidences\"])\n",
    "\n",
    "        print(\"=================================\")\n",
    "        print(f'{len(results)} results')\n",
    "        \n",
    "    if len(results)>k:\n",
    "        return ev[0:k]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Keywords of the query: ['nigerian', 'achebe', 'chinua', 'giant', 'zoo']\n",
      "query --> evidences:nigerian OR keywords:nigerian OR evidences:achebe OR keywords:achebe OR evidences:chinua OR keywords:chinua OR evidences:giant OR keywords:giant OR evidences:zoo OR keywords:zoo\n",
      "-> The iVerify fact-checking process has determined as unproven the claim that the UPND chairperson has been extorting money from businessmen seeking favours or protection. The article claims that Nigerian prophet Seer 1 allegedly exposed the scandal, yet contrary to what was claimed, Seer 1 referred to “some top UPND officials”, without mentioning names. He did threaten to expose names if the act persists. The iVerify team made efforts to reach Blogger Musamba Mumba, but unfortunately without success. The iVerify team further called the Drug Enforcement Commission to substantiate if indeed such acts of money extortion had been received. In response, the Drug Enforcement Commission Public Relation Officer Mr. Kamanga stated that the Commission had not received an official report concerning the case. The iVerify fact checking team attended a press briefing organized by the UPND spokesperson Mr. Cornelius Mwitwa and attended by the UPND Chairperson Mr. Steven Katuka who was asked to give his position concerning the allegations, which he denied. He also challenged those that made the allegations to report the matter to the police and provide evidence. In conclusion, the evidence at the disposal of the iVerify team at this point in time is inconclusive and more research would be needed.  (extortion,extorting,scandal,iverify,musamba,)\n",
      "=================================\n",
      "1 results\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"Show me a proud #Nigerian after today's catastrophic selection dubbed election. An unimaginable ruinous charade exhibited by a country deservedly nicknamed a zoo. How I wish Chinua Achebe is alive today he would have penned down a befitting eulogy for this falling giant\"\n",
    "docs=search(query,'index',3)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Juntamos los dos datasets que tenemos hasta el momento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('iverifyzm.csv')\n",
    "data=data.drop(['Unnamed: 0'], axis=1)\n",
    "for i in range(len(data)):\n",
    "    if data['label'][i]=='True' :\n",
    "        data['label'][i]=2\n",
    "    elif data['label'][i]=='Partly False' or data['label'][i]=='False' or data['label'][i]=='Misleading':\n",
    "        data['label'][i]=0\n",
    "    elif data['label'][i]=='Unproven':\n",
    "        data['label'][i]=1\n",
    "        \n",
    "d=pd.read_csv('africa_check_nigeria.csv')\n",
    "d = d.rename(columns={'claim':'claims'})\n",
    "for i in range(len(d)):\n",
    "    if d['label'][i]=='checked' or d['label'][i]=='Checked':\n",
    "        d['label'][i]=2\n",
    "    elif d['label'][i]=='false' or d['label'][i]=='False' or d['label'][i]=='Fake' or d['label'][i]=='Misleading':\n",
    "        d['label'][i]=0\n",
    "        \n",
    "data=pd.concat([data,d])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraemos los embeddings de las evidencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = 1\n",
    "embedding_train = []\n",
    "evidence_sentences = []\n",
    "for ev in data['evidences']:\n",
    "    print(f\"Analizando {cont}\")\n",
    "    cont += 1\n",
    "    for evs in ev.split('.'):\n",
    "        if len(evs) > 10:\n",
    "            evidence_sentences.append(evs.strip())\n",
    "            embedding_train.append(modelSBERT.encode(evs.strip()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraemos los embeddings de las claims y creamos una nueva lista con las top 5 evidences para cada claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = 1\n",
    "top5 = []\n",
    "for claim in data['claims']:\n",
    "    print(f\"Analizando {cont}\")\n",
    "    cont += 1\n",
    "    emb_claim = modelSBERT.encode(claim.strip())\n",
    "    indx = np.flip(np.argsort(cosine_similarity(emb_claim.reshape(1, -1), embedding_train))[0][-5:])\n",
    "    claim5 = []\n",
    "    for i in indx:\n",
    "        claim5.append(evidence_sentences[i])\n",
    "    top5.append(claim5)\n",
    "    \n",
    "newevidences = []\n",
    "for t in top5:\n",
    "    newevidences.append('. '.join(t))\n",
    "newevidences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos el nuevo dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(zip(data['claims'], newevidences, data['label']), columns = ['claim', 'top5evidences', 'label'])\n",
    "train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
